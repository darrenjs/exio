TODO for libadmin
=================


Phase 2 improvements

* Use json, but, continue to also support SAM

* remove the txContainer stuff

* clean up the public classes, eg, AdminInterface, AdminCommand
  -> don't expose std::vector

* define a welcome banner, instead of the help screen
  -> allow html type output, or, text output etc.

* keep drop_session?

* simply some of the clever things

* admin should not subscribe by default; instead return list of commands

* Allow AdminResponse to take no params, in which case the reqseqno should be
  able to be set automatically.

      exio::AdminResponse hello(exio::AdminRequest& req)
      {
         std::cout << "someone says hello\n";
         return exio::AdminResponse::success();
      }

* support Java

01/11/13
--------

Passed a 7 day run test! So, starting prep for a version cut.



21/10/13
--------

Another thing learnt.  Race conditions can often be teased out under high
load, situations (and, over longer runs, to increase the effective probability
of them occuring).  Under high load, various thread tasks can slow down, or be
temporarily suspended, allowing for unexpected situations to occur.  E.g.,
maybe now it will take seconds for a function to grab a mutex, where normally
it would have taken nanoseconds; and during this increased interval, maybe the
object which owns the function has been deleted!



09/10/13
--------

New bugs, so cannot productionise this weekend.  Two bug are:

(1) fairly reliable memory leak (RSS is in the GB range!)

(2) core dump on the admin side - client pointer is being pushed onto the
    notifq, but by the time it is popped and used, the client object has been
    deleted.


----------------------------------------------------------------------
Tasks for productionisation in 1 week
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- test the large messages with the current GUI; does the GUI support SAM0101?,
  ie, variable length messages?  I.e.,  a SAM header might be like:
     {SAM0101:88889017:



- [DONE] review the logging, looking to reduce

- [DONE] Remove xlog

- Review the IO/TODOs.  Are there any which need to be addressed before
  release?

- [DONE] change poisition of fd() in diags.

- [DONE] review the new alert call; are all addition fields being broadcast?


- DEFERRED: add generic server status requests ... think about how to do this.
      I.e., if we are a server, eg the ximond, can we request that we don't
      prefer for a connected GUI to perform delta-error alerting?  I.e.,
      instead the server might be using the alert api, instead of the error
      field.  However, before I do this, I need to understand how to migrate
      from the error-field approach.

TEST: slow consumer (maybe write a consumer for this, so we can start lots of
      them). exio should detect failure to queue an outbound message; then it
      will no longer queue messages for that client (thus preventing memory
      growth), and will call shutdown(WR) on the socket. Note: not sure if
      this will close the socket though.  However, this is a scenario to now
      explore.

TEST: large files

      --> make code change.  when the client is dropped, make sure the log
          line displays the message size, and the queue limit.

      --> add a TODO for examining how:

          (1) large messages can be sent in parts, and reassembled at the
          client side.  i.e. we need a fragementer.  Each fragement can then
          be placed on the queue, with a delay.

          (2) examine how the admin reply can be changed, so that:

              (a) a message is not always automatically sent by the reply from
              the admin command.  (do this before release?)

              (b) during an admin reply, arbitrary replies can be sent
              directly, ie, how to make a call to the AdminInterface layer to
              allow a reply to be sent.


* [DONE] test dropping of slow consumner

* code review

* svn checkin

* new version number  1.5  (and change the lib number)

----------------------------------------------------------------------

05/10/13  -- possible memory leak

VmPeak:  1432840 kB
VmSize:  1299336 kB
VmLck:         0 kB
VmPin:         0 kB
VmHWM:    107184 kB
VmRSS:      3136 kB
VmData:  1278668 kB
VmStk:       136 kB
VmExe:        76 kB
VmLib:      4940 kB
VmPTE:       180 kB
VmSwap:       68 kB


Why is VmData is large?

Text segment & constants : program code.  read only.

VmData: the initialised, BSS, and heap sections.
        - will grow, as 'brk' and 'sbrk' are called

VmHWM: peak physical memory usage

VM ==> virtual memory. larger that physical memory.

MMU : unit that maps from VM addresses to physical pages.

VM: devided into pages (4K)

paging: when a VM page is moves from storage (swap) into physical


TEXT
DATA
heap
SharedLibraries
stack


free: does free return memory to the system, thus making the process smaller?
Or, is it just placed in the free-list?


----------------------------------------------------------------------
New exio IO system
~~~~~~~~~~~~~~~~~~

* MEDIUM: handling the POLL_PRI poll event; currently not sure what needs to
  be done.

* HARD: enhance the autoconf, so that if it detects gcc, and a later version
  of gcc, then we can use the --static-libstdc++ option to generate a static
  target.  At the moment I think that I am using the option always, and so it
  does generate a compiler warning.

* MEDIUM: on reflection, don't think it is a good idea to public the
  exio_config header; so revert back to what was before.  However, still need
  to find a way to put the exio version number, eg 1.5.1, into a header file
  so that it can be grep'd.

* MEDIUM: writing test code, to test things like the recursive lock

* EASY: alter the arch line, in the diags command, to display something like:
  x86_64 / 64 etc, ie, provide the uname -m used during compilation.  Or,
  instead, should we somehow find the compilation target?  I.e., uname -m will
  just give the details of the host used for compilation, and not necessatily
  the target.

* HARD: do we need to have a more general table-snapshot request, so that we
  can request partial snapshots (eg, selected rows, and selected fields).  I
  thought this might be needed for field-change (via GUI), but not sure
  now. Try to identify any use-cases where this would be useful.

* MEDIUM: in admin command, provide ability to print the raw sam message being
  sent out.  Need this for debugging purposes. Am suprised is it not already
  there.  Probably can add it at the IO layer?  E.g. when AdminSession passes
  a message to be sent.

* MEDIUM: review Reactor.cc; there are some essential TODOs in there.

* EASY: review the files, removing old notes etc that can be often found at
  the top and bottom.

* EASY: rename some of the IO classes, and also rename the files.

* EASY: move the deprecated AdminIO (+ .h) to the attic

* MEDIUM: review the drop_session feature.  Hopefully this should have been
  removed.  However, we need a way at the exio API layer to boot a session.
  E.g., an AdminInterface class method, called drop_session, or something.

* EASY: go through the various thread and mutex C++11 spoof classes, and
  remove the inline constructors and destructors.

* MEDIUM: an improvement can b made in the inbound thread worker method in the
  Client class.  Instead of pulling off all the waiting bytes and then
  invokvng, the client callback, maybe invokve the client callback after each
  waiting chunk is removed.  Why?  In order to avoid huge memory growth.  But
  before doing this, review this suggestion again.

* MEDIUM: I am still not convinced that the bug of chopped writes had been
  resolved.  Ie this is when you doa write followed by a close, the quick
  close will cause some of the final written bytes to be not sent from the
  sender.  Solution is to use shutdown (I think).  So , maybe need to test for
  this, but overall change would be to put ina proper active-close lifecycle,
  which would be begin with a shutdown, the a delay, then a close.

* MEDIUM: in the diags via, for each session, also include its fd number.

* EASY: rename the worker threads of the Reactor, to something like
  inbound_thr, because they are used solely for inbound message flow.

* EASY: the DIAGS admin needs to get thread ID information from the Reactor,
  instead of the admin sessions.

* MEDIUM: test needed.  What happens is we have an AdminSession, attached to a
  Reactor, which suspends the task thread?  At present, I don't think there is
  any inbound queue limitation.

* HARD: I suspect there is still one race condition problem with the new
  socket IO stuff.  The situation could be an AdminSession which passes data
  to the BufferedClient for transmission, followed by the destruction of the
  AdminSession (during which, the AdminSession releases the BufferedClient,
  which in turn requests deletion).  So, is it possible, during a flow control
  event, that a BufferedClient could be destroyed, while it still has data
  which has not yet been written to the socket? I.e., close could be called
  before the data is written?  One thought about this is to put released
  sockets into a shutdown lifecycle; ie, try to ensure their pending data is
  written, and then shutdown is called, and then close is called, before
  performing the actual release.  And, when doing this, ensure that a
  destructing Reactor does not get held up (which is what happened when I
  tried to do this before).

* EASY: make the max pend out configurable

* EASY: check in all the admin support scripts

* EASY: make the ServerSocket timeout internal configurable.

* HARD: review, and maybe redesign, how the Table and DataRow are represented.
  Currently a row is a map of string -> string, ie, column name to value.
  However, this is not so efficient; the holder of the row, DataTable, should
  be the only structure which knows about column names; the DataRow should
  really just hold a vector of values (and a vector of meta).

* MEDIUM: test the ability of the Reactor to be destructed.  I.e. have a test
  server which is able to create/shutdown a second reactor.  At the moment we
  do delete a Reactor instance in AdminInterfaceImpl, but, it has not been
  tested.  One day we might use the AdminInterface inside a xilib instance,
  and those could be destructed and then created.

* HARD: review the container used for session-management in the
  AdminInterfaceImpl, and how session-ids are created/reused etc.

* MEDIUM: the MAX_SESSIONS in AdminInterfaceImpl should come from config.

* MEDIUM: what are the differences between deque<> and list<> ?  Should review
  this for the IO queues which are heavily used.

* EASY: handle    if (nready < 0)   in Reactor.  Just need to log the
  stderror, and sleep before continuing with a retry.

* EASY: in Reactor.cc, there is some logging code which needs to be moved to
  their own function.

* MEDIUM: review the lock around the m_clients list in Reactor.cc.  Is it
  really needed?  Originally it wasn't there, then at sometime it was added.
  I think it is mostly used on the Reactor thread, although, it is also used
  on in the destructor (and that might be the problem).  Also, as part of this
  review, need to review the whole Reactor shutdown.  It think too much it
  being done in the destructor; instread, we should just signal the Reactor
  thread to exit, and then get it to perform the various cleanup operations
  etc.  Also, have a think about when the Reactor should do if there are still
  clients attached during the destruction?  Should it wait for their IO to
  complete?  Or should it close their sockets etc? REVIEW REIVEW REVIEW!

* MEDIUM: review the TODOs in Client.cc, because some of them are important,
  and related to exception handling.

* HARD: need to review the memory strategy, eg, how memory regions are
  copied/passed throughout the inbound and outbound flows, and also during
  message encoding and decoding.

* HARD: one problem in the BufferedClient is that we only grow the memory in
  the ReactorReadBuffer.  We never shrink it down.

* DONE: in the console logger, add timestamp logging

* DONE: in the logging interface, add char* file, int lineno params.

* MEDIUM [LOW] : I have turned off the parsing history.  However, if there is
  a parsing error, it would be nice to give a hint.  So, change the fail so
  that it can be passed a pointer and length, which should be an exceprt of
  the message string being parsed when the error was encountered.

* MEDIUM: measure variable approachs to building strings, eg, stringstream,
  string::operator+, std::string::append, vector, snprint

* HARD: refactor the memory buffer classes, so they are more efficient, and,
  try to avoid copying all the time.  Also, do we need to have a sequence
  number? Because if we don't, then perhaps the message sending can be more
  efficient.

* CRITICAL: see TODO in decodeMsg, because there is a bug in the message
  decoing.  But before fixing it, set up test case framework.

* NEXT-TESTING: continue with all night runs.  Will have to turn off the
  current debug logging of bad messages.

* EASY: is a badmsg arrives, then log that as a warning.  Useful to add this
  sooner rather than later, because will help in debugging.

* MAYBE: the admin leak is related to stdout --- so, perhaps try again, but,
  don't std::cout?

* NEXT: why are the admin's exiting?  Add code to catch the exit, or, signal?
  --> UPDATE: due to memory growth, they are being killed by the system.

* NEXT: why is admin taking up:     VmRSS:   5781052 kB
  --> UPDATE: think it is due to console buffering!

* MEDIUM: need to try by sam decoder on bad messages.  So first, build a test
  harness for it. Then test messages like:

  {SAM0100:<LEN>:::[])   <--- ie, table name is just a colon, etc

* MEDIUM: if I had xlog working, then for the admin (or ./example), I could
  log out the size of the queues.  I suspect the input queue (because that is
  only one the admin should have?) is getting incredible massive.

* HARD-BUG: why do the admins take up so much CPU?

* MEDIUM: find a way to remove the complex QNAME things.  Maybe introduction
  functions instead? Ie, head_tablename(); as a function

* MEDIUM: change the inbound buffer (inteh std::list), so that less memory is
  copied.

* BUG-FIX: need to stop using the std:list, or, at least, stop relying on
  size() and empty()  -- instead, maintain my own count.

* MEDIUM: need to profile the admin comand, to see how much memory it is
  leaking.  So, maybe write a small script which is used to start admin, but
  then watches its usage.

* MEDIUM: have seen that sometimes the admin command exits, when all it is
  doing is receiving a constant stream of data.  So need to add some logging
  code to see why it is terminating.

* MEDIUM: add a trigger to example server, which allows it to exit, which will
  allow progress on the following HARD item:

* HARD: work on destruction of the AdminInterface object, to see if all memory
  is reclaimed.

* MEDIUM: identify the structs which represnet simple chunks of data, and see
  if we can create a common one.

* MEDIUM: add timestamps to the console logger

* MEDIUM: add option to example-server so that it can send messages.

* EASY: change the logging classes, so that the __FILE__ and __LINE__ are just
  additional parameters, instead of pushing them into the ostringstream.  Also
  means we can remove the inc_source method.

* MEDIUM: now that AdminIO is on its way out, need to provide ways to get the
  number of bytes read/written etc, from the standard client.

* MEDIUM: in Reactor class, look to improve the writing of Ctrl messages to
  the internal pipe. I.e., handle failures.

* MEDIUM: there are functions like Bind which are defined in multiple places.
  Move then into a header?  I.e. see the copyright notice on the unp.h header,
  because most of them are from there (and, start to remove the throwing of
  exceptions).

* EASY: refactor the Reactor so that it only relies on LogSvc class, and not
  AppSvc.

* DONE: write a new test (server) program for generating lots of data on a
  table, so that when I perform load tests, I can test clients which connect
  and receive lots of data.

* EASY: write a test (client) program which will send high volume of data.

* test the "example" program has a memory leak, which is probably found in Reactor.

* MEDIUM: add method to client to allow a wait until data written. UPDATE:
  this has been written, but now needs testing.  Need to create the situation
  where the socket write is slowed down (maybe a sleep in the Reactor), so
  that the wait can be tested.

* HARD: move the server socket thread into the Reactor.  I.e., then we can
  remove that thread too.  But, what about housekeeping?

* DESIGN: decouple the Client from the AdminSession.  Should not be based on
  inheritance, but instead just an interface class for callback. UPDATE:  do
  we really need this?  What is the beneit?

* Threading: need to add a recursive lock

* DESIGN ISSUE: we have a problem if the TASK thread, going into a client
  callback, causes the destruction of the client object.  Not sure how to
  fully handle this, but two parts of the problem are th recursie lock and the
  doupleing of the client from the adminsession.

* HIGH: need to handle situation where max number of clients is reached.  This
  will likely be an exception or return-balue form add_client. Start with
  add_client in the reactor.

* HARD: in the client, need a method to write/close/wait-for-completion
  ... this is needed so that UA which want to ensure data is written can do
  so.

* HARD: need to test the sending / receiving of VERY LARGE messages

* HARD: move the housekeeping thread into the Reactor?

* HARD: build using FreeBSD

* HARD: improvement to the IO.  Many connections to an exio based server might
        only listen to data, and not send SAM requests (aside from heartbeats
        and logons).  For these, can we use a shared task thread instead of a
        dedicated thread?

* HARD / Longterm : is there a way to use SQLite internally within exio? That
  way we would be able to support select statements.  Could also use it to
  persiste to disk.  But, would it be too heavy-weight?

Work: new approach to snapshots

- raw table is converted into a txMessage type structure
- AI::send_one
  -> enqueueToSend
  ->  protocol.encodeMsg



----------------------------------------------------------------------
NEXT
----


* slow-consumer  (see socket notes below)

  -> using the new slow-consumer tool, set up a repeatible scenario, so that
     we can have a server publishing data, connected to several slow
     consumers.  Need to be able to monitor, via netstat and diags adin
     command, the size of queued data.

  -> introduce configuration for limiting the size of the queue.


  -> recap: which of the two IO threads is responsible for closing the
     connection?

  -> the BIG UNKNOWN is how to close a session if the size is exceeded.
     Currently, we close a session by placing special data on the queue.
     However, we cannot take that approach now, because the queue will be
     full.  So will likely need a new method, close_immediately(), which stops
     socket IO even if there is pending data. This might require a new atomic
     variable, or someting like that.


* move the Atomic classes from their current location, and into the libcpp
  stuff.  Also rename to match the C++11 eqivalients, and, use the same method
  names as them.

* need a new constructor to AdminCommand, which can take a global function

* can we remove the m_sessions.lock?

  -> YES: but, we still will need synchronization in order to avoid the
     "reset-read" race condition

* TODO: write a note about his "reset-read" race condition, perhaps create a
  new HOWTO_race_condition.txt, to start collecting types of race conditions.

* So two solutions: either use smart pointers, or, add row locking.  I think I
  will go for the row locking, because that is just a simple case of adding a
  mutex to the row structure.  Having per-row locking is not ideal, however,
  it just be more performant than just having a global lock.  And, at least I
  fully understand the model that I am using.

* A further improvement wouldbe to use read-write locks.  However, if I do
  that, beware that the AdminSession class is not lock
  single-thread-synchronized (which it current is, because all threads have to
  go via the sessions.lock).

* why are locks needed?  In order to prevent a writer modifying a structure
  while there are other readers and writers using the structure.  Because,
  that can invalidate the structure.

----------------------------------------------------------------------
SOCKET NOTES  (AdminIO)
-----------------------


* class needs to be cleaned up

* need to document the design, ie, coordinated closure comes from the write
  thread, and there are deliberate efforts to coordinate the shutdown of
  threads..

* try to remove the use of exceptions, since I've seen the trouble these can
  cause!

* why is there a comment about the socket perhaps being non-blocking?

* standardise the socket logging, such that the fd number is always included
  in the message

* note down the various test situations:

  - slow consumer, ie, enqueue data reached maximum, and so socket must be
    immediately terminated, with data loss

  - coordinated closure, after last data sent.

  - read() flow control

  - write() flow control

  - read error / end of stream

  - write error / end of stream

  - object deleted, but with call to request stop


----------------------------------------------------------------------
TIDY-UP tasks
-------------

* should use a map for list of open sessions, because problem with a fixed
  array, is that, while theoretically faster, really only works for Xi style
  connections, ie, a small number of clients that remain connected all day.

* the error codes need to be moved to the AdminCommand.h file

* session-ID : currenty is just a unique integer.  However, what happens if it
  wraps around?  Is there a danger?  Well, risk is that we have aliasing, ie,
  some long running code says give me session 100, but, 100 is no longer the
  same session; there has been a disconnect & reconnect in that time.  Only
  way to help prevent this problem is to have a timestamp in the ID also.
  Should not be too hard to add.

----------------------------------------------------------------------
Improvement: Protect exio from bad messages
-------------------------------------------

Really ought to implement a max message size. At the moment, a bad message
like:

{SAM0100:99999999999999999999  ....

...would probably kill the server.  At the moment, have implemented a 2G
maximum inbound message size.

----------------------------------------------------------------------
Improvement: Avoid memory copy for encoding messages
----------------------------------------------------

This has been a problem for ages.  In the message queue, where QueuedItem (?)
objects are pushed, the encode messages are copied all the time, via object
copies. This is ofcourse very bad. In stead, we should be pushing smart
pointers on the queue, either some kind of C++ smart pointer, or, instead just
make sure objects are cleaned up for all kinds of life-time end.

----------------------------------------------------------------------
Feature: detect closed session
------------------------------

>> see example.cc, Admin_LotsOfNumbers::invoke

During a long running admin command, it would be good if the admin thread
could check if the session is still open, ie, that the remote admin-session
has not terminated.

Currently, it is not straight forward to do this, because the thread that has
just read from the socket (the client-handler) is the thread that is inside
the admin-callback code.  Normally it is that thread which would detect a
socket disconnect.

One approach for testing is a session is still open is to try to send a
heartbeat.  However, need to be careful if such a test was invoked from a
tight loop; we don't want to send millions of hbs per second to the peer.

So, perhaps the threading model needs to be changed?  E.g., instead of the
approach of a client-handler thread, instead have a single thread which
collects requests from all connected sockets (and the LISTEN socket), and then
dispatches the requests to a handler, which in turn, will process the admin
request.

NOTES: make notes about the different designs for server applications

- 1 dedicated thread per client

- 1 process per client (forking server)

- 1 thread per client request

- also, consider the pros/cons for each approach, eg, low latency etc. And,
  avoid the problem of parallel sessions being blocked because of a slow
  admin.  And, related, is how we associate sessions to the session-object.
  E.g., do we use an array or a map, etc.

----------------------------------------------------------------------
ALL
---

* Consider added ordering information to txContainer, so that the order in
  which items are added can be later retrieved.

* [EASY] There are now two places where username is provided: at logon, and on
  each command.  This is for legacy reasons.  However, if a useranem was
  provided at logon, then we should not permit later admin commands to change
  the username.  So when building teh AdminRequest, insert the username as a
  member of the class, and, when constructing the AdminReqeust, check that
  there is no difference between the session-username and command-username
  (unless sessions-username was empty ... against, to support legacy GUIs).

* [MEDIUM] Introduce provide AtomicInt & AtomicBool classes

* [EASY] Allow it to be configured whether the RowLastUpdated is automatically
         added or not.

* [EASY] Allow heartbeats, on a per session basis, to be option. Can have a
  field in the logon message.

* [EASY] in send_one(LIST), we loop ver each message and call the enque for each.
  Instead, have a mthod on the IO that takes a list, this is to avoid
  interleaving of snapshots etc.

* [EASY] rmeove old _nolock_send_snapshopt_as_single_msg

* prefer to use check_enc_size, because of the margin etc.  ie remove uses of
  the other function, which calcs msg size.

* [MEDIUM/HIGH] - have noticed that even when the regsim has gone down, ximond
  is still sending regular updates, eg, below.  Need to investigate why these
  are being sent, and then resolve.

{SAM0100:00029:heartbeat:[]}
{SAM0100:00161:tableupdate:[head=[tablename=xi.hosts,msgtype=tableupdate,],body=[rows=1,row_0=[RowKey=xi.uat.zurichH,RowLastUpdated=2013/02/10 16\:58\:39,],],]}
{SAM0100:00161:tableupdate:[head=[tablename=xi.hosts,msgtype=tableupdate,],body=[rows=1,row_0=[RowKey=xi.uat.zurichH,RowLastUpdated=2013/02/10 16\:56\:06,],],]}
{SAM0100:00161:tableupdate:[head=[tablename=xi.hosts,msgtype=tableupdate,],body=[rows=1,row_0=[RowKey=xi.uat.zurichH,RowLastUpdated=2013/02/10 16\:58\:44,],],]}
{SAM0100:00161:tableupdate:[head=[tablename=xi.hosts,msgtype=tableupdate,],body=[rows=1,row_0=[RowKey=xi.uat.zurichH,RowLastUpdated=2013/02/10 16\:56\:06,],],]}
{SAM0100:00029:heartbeat:[]}


* [HARD] "Big Message Problem" - this is the problem where a single txMessage
  is too large to be encoded.  Eg. it could be something as simple as a filed
  name being very very long.  Or maybe there are cases where the protocol
  window is smaller.  Whatever.  The problme remains that we have a txMessage
  whic, as currently implemented, cannot be serialised into a SAM message.  So
  the solution has to be message fragmenting.  This requires support on both
  sender and receiver (which also means the Java GUI needs updating).  So next
  thing is to sit down and design this out.

* [HARD] for estimation of size, we need to consider cases where a single row,
  or even part of a row, like the fielname or field value, might already
  exceed the max msg size.  Just adding up the parts is not enought, because
  the counter could wrap around.  So need to review the calc-message-size
  routine.  This should be esay to test though, by reducing the buffer size.

* [HARD] another approach to encoding large messages is to send a fully
  encoded message in chunks, which must be reassemlbed at the receiver site.

* [DONE] Allow use of keepalive to be configured

* [DONE] move the string_error function into a common location, and use
  whereever strerror is currently called.

* [DONE] - add heatbeating.

* Use smart_ptrs and dynamic memory instead of the current QueuedItem
  class. The QueuedItem stores its buffer via stack array; advantage is that
  there is no memory management required, but disadvantage is that lots of
  memory copying is taking place.  A better approach would be to dynamically
  allocate some memory just before we encode a Message, and then pass a
  pointer around, until the raw bytes been writted.  This approach however
  will require some kind of smart pointer for safest approach, or, I could
  instead have the Queued Item only deallocate its memory when release() is
  called.  Also, with QueuedItem, only the last holder of the item really
  needs to memory; ie., once a copy has been taken, the memory ownership has
  moved out.

* ximon.gui table events.  A current problem in the ximon gui is that we have
  to hard-code teh table name and column name of xihosts.connection, so that
  when a TCP connection to a server is lost, we can set the connectivity
  status to down.  To make this generic, the source tables need to define a
  set of EventActions that should apply in the case of a disconnect event.
  Need to spell out the logic for this, and then add support in both the
  ximon.gui and exio admin server.  Start with a design for this, then
  implement the simplest version. Later we can consider having regexp matching
  etc.

* exio / ximon.  Standardise the approach to column styles. Currently is a bit
  of a mess and not well defined.  Basically, we need to allow the end user to
  specify various presentation styles for their columns, and they styles need
  to be supported by the GUI.  The GUI should not do anything, by default.

* [VHARD] exio.  How can we reduce the number of threads?  Can we have 1 thread per
  session, instead of two?  Can we have 1 thread to handle all sessions?

* ximon.gui -- is the GUI currently sending logon messages?

* exio & clients : need a mechanism to support message splitting and
  recombination.

* exio & clients: should we group admin commands into categories?

* [HARD] exio : change the session ID so that it can wrap-around.  The current
  one cannot.  Use something like a pending array with a wrap around mask.
  This means we will only be able to support a fixed number of simulataneous
  clients, which is fine for now.

* [HARD] exio router. Would be nice to have a generic router, which connects
  to other exio services, and then unifies them, so that clients which cannot
  reach colo hosts instead can use the exio router (exiord). Need a design.

* ximon.gui.  The "Delete All Rows" option is misleading, because it deletes
  all rows in table XYZ, now just the visible row.  So consider renaming this
  option. Also, is it possible to provide an option like "delete all visible
  rows".

* ximon.gui: When opening an admin pane, the title is just "Admin". Instead,
  can we provide a better title, something that suggests which server is being
  admin'd.

* exio:  provide user authentication

* ximon.gui: provide an option in the Admin pane to allow a command to be sent
  repeatedly.

* support individual row deletion.  This would require support in the
  ximon.gui also.

* ximon.gui & exio.  If the user clicks on delete row, should the gui send a
  message to all connected sessions, requesting a snapshot?

* exio hardening: make core classes (eg SAM structures etc) exception and
  thread safe in the copy constructors and assignment operators.

* Improv: "xi.services" string appears everywhere ... make a constant. Same
  for lots of its fields.

* Improvement: ximond program should really have a main application facade
  class.

* BUG: at moment, if regsim is killed (or ximond loses connection to regsim),
  ximond is currently not setting the state of its processes to down.

* DESIGN PROBLEM.  In the GUI, if we click "Delete all rows", the table is
  cleared.  However, the data source is now only sending table updates, thus,
  the full table contents don't be repopulated.

* DESIGN PROBLEM.  When we have a lock protecting a collection, it is always
  safe to take the approach of taking a copy of the collection while locked,
  and then iterating over the collection outside of the lock?  Whole point is
  to reduce the lock scope.

* Add the AdminCommand button, to the xi.services table. Lots of stuff
  involved with this piece of work.

* Introduce a callback mechanism to the monitor.  This is so that the client
  application can be notified on events on tables.  The implementation should
  be based on the callback framework that Session's use to subscribe to
  tables, ie, the Session and Client are just to instances of a callback base
  class.  So the first step in this tasks to introduce a base-class callback &
  events and get the Session callback to be based on them.

* Rationalise the main AdminInterface header file.  Possible rename to pcam.h,
  or whatever package name we eventually use?  Also, take a look at what
  header files are being exported, because after recent refactoring, some of
  them may no longer be needed.

* [DONE] Remove the table_clear from Admin commands.

* move the thread_queue inside of the QueueWriter, and add internal locking
  there.  Also, inside the locking scope, include the isStopping flag, and
  maybe add a new flag, isDone.  Point is, there is some code in
  AdminSession::~AdminSession which will call close_fast, and we want to have
  a way of briefly waiting for that queue to be written to socket before
  closing close_fast.

* admin needs to be able to display tabular data

* decide: in the admin output to console, should we indicate if there is more
  to follow?

* add a debug flag to admin, to see the raw messages etc.

* why are there so many TIME_WAIT sockets? I don't think it is due to the
  ::shutdown call, so what is calling it?

* instead of a blocking read, or a read with a timeout, instead use select
  with a second file descriptor, which we can write to when we want the reader
  thread to unblock.

----------------------------------------------------------------------
UNCLASSIFIED
------------

* Change project name, to "expose" maybe?

* split sam.h so that the tx types can be used included on their own. I.e, sam
  has nothing to do with tx.

* format into an autoconf project
  -> learn how to use auto conf
  -> devise what the structure of the code/build should look like

* For some of the tx containers, use the swap approach for writing exception
  safe operator=

* remove INFO type lines.  I don't want that style of logging.

----------------------------------------------------------------------
TEST CASES
----------

while true; do ./admin 127.0.0.1 33333 list; done

----------------------------------------------------------------------
DONE
----


* the sam decode must discard a connection is the leading bytes don't look
  like a SAM message.


----------------------------------------------------------------------
DESIGN DISCUSSION
-----------------


* I used to have an admin command to delete tables.  This command was part of
  the AdminInterface/Monitor class, to every application would automatically
  have the ability to allow a remote admin command to clear a table.  However,
  this turns out not to be such a good idea: allowing a table to be cleared
  via a remote admin command means the client application, which is
  responsible for updating the table, now has assume that its tables could be
  cleared at any time.  I.e., on each table update iteration, the client now
  has to check if the table has been cleared (and if so, repopulate with
  static content); or, I need to introduce table-event callbacks into the
  client.  Note that at some point client-callbacks will likely be added, but,
  I am still unsure about adding admin commands (at the AdminInterface level)
  that can clear/drop tables.  If a client application wants that
  functionality, then they can add it.

Put locks on the outside of DataTable?
--------------------------------------

/*
 * TODO: consider placing the table lock on the outside?  -> the main problem
 * with that is that it is going to be hard to ensure proper locking, ie, we
 * canot be certain that all future code writte, that access the table, will
 * properly call lock and unlock before methods calls.
 */

----------------------------------------------------------------------
